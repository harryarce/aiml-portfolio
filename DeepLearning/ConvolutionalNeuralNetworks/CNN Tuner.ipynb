{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper-parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U keras-tuner\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "#helper libraries\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#print (tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the format of pixel values to float and normalize the pixel values\n",
    "\n",
    "img_train = img_train.astype('float32') / 255\n",
    "\n",
    "img_test = img_test.astype('float32') / 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model:\n",
    "\\\n",
    "when you build your model for hyper tuning,\n",
    "\n",
    "for each hyperparameter to be tuned, you need to define a search range or search space\n",
    "The tuner will use the values defined in search range to find the best value of hyperparameter\n",
    "\n",
    "the model that you set up for hypertuning is called a hypermodel\n",
    "\n",
    "Two approaches to define a hypermodel:\n",
    "\n",
    "1.  using a model build function\n",
    "\n",
    "2.  using predefined subclasses of hypermodel class of keras tuner API\n",
    "\n",
    "two predefined subclasses:  HyperXception and HyperResNet\n",
    "\n",
    "the model builder function returns us a compiled model and users hyperparameters you define inline to hypertune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "    #model.add(keras.layers.Dense(128, activation='relu'))   Original line\n",
    "\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)  # parameter I want to tune, + range of possible values\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))  # first parameter is what I want to tune.  ex.  units\n",
    "\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.01,0.001,0.0001])  # parameter I want to tune, valid values \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),  # only parameter i want to tune\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # convert output into probabilities array to do cross entropy\n",
    "                metrics=['accuracy']\n",
    "            ) #\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instantiate the tuner\n",
    "Keras tuner library has 4 tuners to offer\n",
    "\n",
    "1. RandomSearch\n",
    "2. Hyperband\n",
    "3. BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner builds and runs new models from all combinations between hyperparameters\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                objective='val_accuracy',  \n",
    "                max_epochs=10,\n",
    "                factor=3,\n",
    "                directory='my_dir',\n",
    "                project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**early stopping**: helps you in controlling overfitting\n",
    "creating callbacks to stop training early after reaching a certain value of validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 09s]\n",
      "val_accuracy: 0.8806666731834412\n",
      "\n",
      "Best val_accuracy So Far: 0.8886666893959045\n",
      "Total elapsed time: 00h 19m 24s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5)\n",
    "\n",
    "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "#hyperparameters\n",
    "#number of nodes\n",
    "# learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the optimal number of units is 448.\n",
      "the best learning rate is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "the optimal number of units is {best_hps.get('units')}.\n",
    "the best learning rate is {best_hps.get('learning_rate')}.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 9s 5ms/step - loss: 0.4956 - accuracy: 0.8250 - val_loss: 0.3931 - val_accuracy: 0.8576\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3685 - accuracy: 0.8658 - val_loss: 0.3649 - val_accuracy: 0.8678\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3306 - accuracy: 0.8785 - val_loss: 0.3383 - val_accuracy: 0.8756\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3049 - accuracy: 0.8872 - val_loss: 0.3414 - val_accuracy: 0.8767\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2852 - accuracy: 0.8950 - val_loss: 0.3226 - val_accuracy: 0.8827\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2700 - accuracy: 0.8992 - val_loss: 0.3449 - val_accuracy: 0.8802\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2561 - accuracy: 0.9046 - val_loss: 0.3105 - val_accuracy: 0.8883\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2451 - accuracy: 0.9075 - val_loss: 0.3196 - val_accuracy: 0.8855\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.2314 - accuracy: 0.9137 - val_loss: 0.3333 - val_accuracy: 0.8857\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2244 - accuracy: 0.9164 - val_loss: 0.3202 - val_accuracy: 0.8862\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2154 - accuracy: 0.9202 - val_loss: 0.3310 - val_accuracy: 0.8891\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.2089 - accuracy: 0.9216 - val_loss: 0.3149 - val_accuracy: 0.8897\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1986 - accuracy: 0.9248 - val_loss: 0.3228 - val_accuracy: 0.8903\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1918 - accuracy: 0.9283 - val_loss: 0.3180 - val_accuracy: 0.8957\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1862 - accuracy: 0.9311 - val_loss: 0.3426 - val_accuracy: 0.8935\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1781 - accuracy: 0.9329 - val_loss: 0.3256 - val_accuracy: 0.8932\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1740 - accuracy: 0.9340 - val_loss: 0.3309 - val_accuracy: 0.8953\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1684 - accuracy: 0.9370 - val_loss: 0.3619 - val_accuracy: 0.8895\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1630 - accuracy: 0.9392 - val_loss: 0.3656 - val_accuracy: 0.8905\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1589 - accuracy: 0.9402 - val_loss: 0.3439 - val_accuracy: 0.8896\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1534 - accuracy: 0.9430 - val_loss: 0.3662 - val_accuracy: 0.8932\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1478 - accuracy: 0.9440 - val_loss: 0.3807 - val_accuracy: 0.8912\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1435 - accuracy: 0.9467 - val_loss: 0.3722 - val_accuracy: 0.8942\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1422 - accuracy: 0.9472 - val_loss: 0.3682 - val_accuracy: 0.8957\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1379 - accuracy: 0.9488 - val_loss: 0.3632 - val_accuracy: 0.8945\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1317 - accuracy: 0.9512 - val_loss: 0.4042 - val_accuracy: 0.8890\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1277 - accuracy: 0.9524 - val_loss: 0.3858 - val_accuracy: 0.8915\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1268 - accuracy: 0.9531 - val_loss: 0.4040 - val_accuracy: 0.8923\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1226 - accuracy: 0.9540 - val_loss: 0.4194 - val_accuracy: 0.8899\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1165 - accuracy: 0.9572 - val_loss: 0.4052 - val_accuracy: 0.8923\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1150 - accuracy: 0.9567 - val_loss: 0.4212 - val_accuracy: 0.8906\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1128 - accuracy: 0.9568 - val_loss: 0.4135 - val_accuracy: 0.8927\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1086 - accuracy: 0.9588 - val_loss: 0.4440 - val_accuracy: 0.8900\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1078 - accuracy: 0.9598 - val_loss: 0.4133 - val_accuracy: 0.8961\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1009 - accuracy: 0.9620 - val_loss: 0.4421 - val_accuracy: 0.8957\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1060 - accuracy: 0.9600 - val_loss: 0.4596 - val_accuracy: 0.8943\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0974 - accuracy: 0.9630 - val_loss: 0.4374 - val_accuracy: 0.8943\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0992 - accuracy: 0.9628 - val_loss: 0.4330 - val_accuracy: 0.8968\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0958 - accuracy: 0.9635 - val_loss: 0.4329 - val_accuracy: 0.8924\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0922 - accuracy: 0.9654 - val_loss: 0.4744 - val_accuracy: 0.8924\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0906 - accuracy: 0.9661 - val_loss: 0.5051 - val_accuracy: 0.8879\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0892 - accuracy: 0.9669 - val_loss: 0.4820 - val_accuracy: 0.8934\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0882 - accuracy: 0.9673 - val_loss: 0.4808 - val_accuracy: 0.8928\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0842 - accuracy: 0.9683 - val_loss: 0.4766 - val_accuracy: 0.8938\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0858 - accuracy: 0.9682 - val_loss: 0.4894 - val_accuracy: 0.8967\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0818 - accuracy: 0.9699 - val_loss: 0.4883 - val_accuracy: 0.8930\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0801 - accuracy: 0.9699 - val_loss: 0.4734 - val_accuracy: 0.8976\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0769 - accuracy: 0.9708 - val_loss: 0.5104 - val_accuracy: 0.8952\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0781 - accuracy: 0.9717 - val_loss: 0.5222 - val_accuracy: 0.8934\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0733 - accuracy: 0.9730 - val_loss: 0.5426 - val_accuracy: 0.8945\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "new_model = model.fit(img_train, label_train, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 47\n"
     ]
    }
   ],
   "source": [
    "# tune epochs value\n",
    "val_acc_per_epoch = new_model.history['val_accuracy']\n",
    "\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "\n",
    "print ('Best epoch: %d' %(best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.4933 - accuracy: 0.8257 - val_loss: 0.3891 - val_accuracy: 0.8602\n",
      "Epoch 2/47\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.3689 - accuracy: 0.8637 - val_loss: 0.3554 - val_accuracy: 0.8725\n",
      "Epoch 3/47\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.3291 - accuracy: 0.8779 - val_loss: 0.3447 - val_accuracy: 0.8773\n",
      "Epoch 4/47\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.3034 - accuracy: 0.8875 - val_loss: 0.3164 - val_accuracy: 0.8843\n",
      "Epoch 5/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2849 - accuracy: 0.8941 - val_loss: 0.3226 - val_accuracy: 0.8852\n",
      "Epoch 6/47\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2695 - accuracy: 0.9000 - val_loss: 0.3355 - val_accuracy: 0.8802\n",
      "Epoch 7/47\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.2540 - accuracy: 0.9036 - val_loss: 0.3538 - val_accuracy: 0.8742\n",
      "Epoch 8/47\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2443 - accuracy: 0.9086 - val_loss: 0.3163 - val_accuracy: 0.8875\n",
      "Epoch 9/47\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.2326 - accuracy: 0.9124 - val_loss: 0.3072 - val_accuracy: 0.8901\n",
      "Epoch 10/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2224 - accuracy: 0.9162 - val_loss: 0.3239 - val_accuracy: 0.8882\n",
      "Epoch 11/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2124 - accuracy: 0.9212 - val_loss: 0.3208 - val_accuracy: 0.8881\n",
      "Epoch 12/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2066 - accuracy: 0.9222 - val_loss: 0.3151 - val_accuracy: 0.8925\n",
      "Epoch 13/47\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1960 - accuracy: 0.9272 - val_loss: 0.3233 - val_accuracy: 0.8917\n",
      "Epoch 14/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1909 - accuracy: 0.9281 - val_loss: 0.3110 - val_accuracy: 0.8946\n",
      "Epoch 15/47\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1843 - accuracy: 0.9303 - val_loss: 0.3386 - val_accuracy: 0.8913\n",
      "Epoch 16/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1776 - accuracy: 0.9334 - val_loss: 0.3520 - val_accuracy: 0.8864\n",
      "Epoch 17/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1707 - accuracy: 0.9349 - val_loss: 0.3386 - val_accuracy: 0.8932\n",
      "Epoch 18/47\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1669 - accuracy: 0.9368 - val_loss: 0.3296 - val_accuracy: 0.8946\n",
      "Epoch 19/47\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1585 - accuracy: 0.9394 - val_loss: 0.3651 - val_accuracy: 0.8900\n",
      "Epoch 20/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1592 - accuracy: 0.9396 - val_loss: 0.3605 - val_accuracy: 0.8893\n",
      "Epoch 21/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1495 - accuracy: 0.9440 - val_loss: 0.3624 - val_accuracy: 0.8902\n",
      "Epoch 22/47\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1460 - accuracy: 0.9456 - val_loss: 0.3474 - val_accuracy: 0.8930\n",
      "Epoch 23/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1443 - accuracy: 0.9458 - val_loss: 0.3521 - val_accuracy: 0.8903\n",
      "Epoch 24/47\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1375 - accuracy: 0.9486 - val_loss: 0.3401 - val_accuracy: 0.8974\n",
      "Epoch 25/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1354 - accuracy: 0.9484 - val_loss: 0.3781 - val_accuracy: 0.8907\n",
      "Epoch 26/47\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1306 - accuracy: 0.9500 - val_loss: 0.3929 - val_accuracy: 0.8888\n",
      "Epoch 27/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1256 - accuracy: 0.9530 - val_loss: 0.3618 - val_accuracy: 0.8954\n",
      "Epoch 28/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1262 - accuracy: 0.9529 - val_loss: 0.3964 - val_accuracy: 0.8919\n",
      "Epoch 29/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1196 - accuracy: 0.9547 - val_loss: 0.3812 - val_accuracy: 0.8944\n",
      "Epoch 30/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1175 - accuracy: 0.9553 - val_loss: 0.4025 - val_accuracy: 0.8922\n",
      "Epoch 31/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1151 - accuracy: 0.9574 - val_loss: 0.3945 - val_accuracy: 0.8926\n",
      "Epoch 32/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1110 - accuracy: 0.9581 - val_loss: 0.3936 - val_accuracy: 0.8939\n",
      "Epoch 33/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1102 - accuracy: 0.9579 - val_loss: 0.4056 - val_accuracy: 0.8932\n",
      "Epoch 34/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1053 - accuracy: 0.9602 - val_loss: 0.4401 - val_accuracy: 0.8867\n",
      "Epoch 35/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1020 - accuracy: 0.9617 - val_loss: 0.4271 - val_accuracy: 0.8960\n",
      "Epoch 36/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1002 - accuracy: 0.9633 - val_loss: 0.4445 - val_accuracy: 0.8900\n",
      "Epoch 37/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1004 - accuracy: 0.9618 - val_loss: 0.4369 - val_accuracy: 0.8909\n",
      "Epoch 38/47\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0932 - accuracy: 0.9647 - val_loss: 0.4886 - val_accuracy: 0.8860\n",
      "Epoch 39/47\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0950 - accuracy: 0.9644 - val_loss: 0.4961 - val_accuracy: 0.8902\n",
      "Epoch 40/47\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0915 - accuracy: 0.9660 - val_loss: 0.4722 - val_accuracy: 0.8923\n",
      "Epoch 41/47\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0877 - accuracy: 0.9672 - val_loss: 0.4379 - val_accuracy: 0.8947\n",
      "Epoch 42/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0937 - accuracy: 0.9645 - val_loss: 0.4709 - val_accuracy: 0.8928\n",
      "Epoch 43/47\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0854 - accuracy: 0.9679 - val_loss: 0.4738 - val_accuracy: 0.8940\n",
      "Epoch 44/47\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0834 - accuracy: 0.9680 - val_loss: 0.5109 - val_accuracy: 0.8947\n",
      "Epoch 45/47\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0799 - accuracy: 0.9698 - val_loss: 0.5091 - val_accuracy: 0.8922\n",
      "Epoch 46/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0821 - accuracy: 0.9688 - val_loss: 0.5143 - val_accuracy: 0.8913\n",
      "Epoch 47/47\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0790 - accuracy: 0.9699 - val_loss: 0.5162 - val_accuracy: 0.8953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x219dbc58b80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "hypermodel.fit(img_train,label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f7ef0cda6a04710cc4343b21cb65babb8f3c2db92aca7a265f09c49a9bab6ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
